{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fa8e4d",
   "metadata": {},
   "source": [
    "# Laboratorium 11 - Spadek wzdłuż gradientu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d4fac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29693631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import linalg\n",
    "\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c2f72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"breast-cancer.labels\", header=None, names=[\"name\"])\n",
    "column_names = labels[\"name\"].tolist()\n",
    "\n",
    "\n",
    "train_data = pd.read_csv(\"breast-cancer-train.dat\", header=None, names=column_names)\n",
    "validate_data = pd.read_csv(\n",
    "    \"breast-cancer-validate.dat\", header=None, names=column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1430d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reprezentacja liniowa\n",
    "A_train_linear = train_data.drop([\"patient ID\", \"Malignant/Benign\"], axis=1).values\n",
    "A_validate_linear = validate_data.drop(\n",
    "    [\"patient ID\", \"Malignant/Benign\"], axis=1\n",
    ").values\n",
    "\n",
    "# Reprezentacja kwadratowa\n",
    "selected_features = [\n",
    "    \"radius (mean)\",\n",
    "    \"perimeter (mean)\",\n",
    "    \"area (mean)\",\n",
    "    \"symmetry (mean)\",\n",
    "]\n",
    "\n",
    "\n",
    "def create_quadratic_features(data):\n",
    "    quadratic_features = data[selected_features].copy()\n",
    "    for feature in selected_features:\n",
    "        quadratic_features[f\"{feature}^2\"] = data[feature] ** 2\n",
    "    for i in range(len(selected_features)):\n",
    "        for j in range(i + 1, len(selected_features)):\n",
    "            feature1 = selected_features[i]\n",
    "            feature2 = selected_features[j]\n",
    "            quadratic_features[f\"{feature1}*{feature2}\"] = (\n",
    "                data[feature1] * data[feature2]\n",
    "            )\n",
    "    return quadratic_features.values\n",
    "\n",
    "\n",
    "A_train_quadratic = create_quadratic_features(train_data)\n",
    "A_validate_quadratic = create_quadratic_features(validate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c0e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wektor b dla zbioru treningowego\n",
    "b_train = np.array([[1, 0] if row == \"M\" else [0, 1] for row in train_data[\"Malignant/Benign\"]])\n",
    "\n",
    "# Wektor b dla zbioru walidacyjnego\n",
    "b_validate = np.array([[1, 0] if row == \"M\" else [0, 1] for row in validate_data[\"Malignant/Benign\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    Z -= np.max(Z, axis=1).reshape(-1, 1)\n",
    "    E = np.e ** Z\n",
    "    SUM = np.sum(E, axis=1).reshape(-1, 1)\n",
    "    P = E / SUM\n",
    "    \n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f93c311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xentropy(S, T):\n",
    "    n = len(S)\n",
    "    return - (np.sum(T * np.log(S)) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e950cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_xentropy(X, S, T):\n",
    "    n = len(S)\n",
    "    return X.T @ (S - T) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "206bc1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(W, X):\n",
    "    sf_max = softmax(X @ W)\n",
    "    return (sf_max == np.max(sf_max, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf8544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc(P, T):\n",
    "    accuracy = np.sum(P * T) / P.shape[0]\n",
    "    return 100.0 * accuracy\n",
    "\n",
    "\n",
    "def print_log(step, cost, train_acc, val_acc):\n",
    "    log = 'Step {:3d}\\tcost value: {:5.2f},\\ttrain accuracy: {:5.2f},\\t' \\\n",
    "          'validation accuracy: {:5.2f}'\n",
    "    log = log.format(step, cost.item(), train_acc.item(), val_acc.item())\n",
    "    \n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd_fit(W0, X, T, X_val, T_val, lr=1.0, steps=100, log_every=5):\n",
    "    n = X.shape[0]\n",
    "    W = np.copy(W0)\n",
    "    M = 0\n",
    "    mu = 0.9\n",
    "    \n",
    "    for step in range(steps):\n",
    "        sf_max = softmax(X @ W)\n",
    "        cost_val = xentropy(sf_max, T)\n",
    "        \n",
    "        cost_grad = grad_xentropy(X, sf_max, T)\n",
    "        M = mu * M - lr * cost_grad\n",
    "        W = W + M\n",
    "        \n",
    "        P_train = classify(W, X)\n",
    "        train_acc = calc_acc(P_train, T)\n",
    "        \n",
    "        P_val = classify(W, X_val)\n",
    "        val_acc = calc_acc(P_val, T_val)\n",
    "        \n",
    "        if step == 0 or (step + 1) % log_every == 0:\n",
    "            print_log(step+1, cost_val, train_acc, val_acc)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c469e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATA_eigenvalues, _ = np.linalg.eig(A_train_linear.T @ A_train_linear)\n",
    "lambda_min = np.min(ATA_eigenvalues)\n",
    "lambda_max = np.max(ATA_eigenvalues)\n",
    "condition_no = lambda_max / lambda_min\n",
    "\n",
    "#conservative learning rate due to very high condition coefficient\n",
    "lr = 1 / lambda_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88b509ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 31) (300, 2) (260, 31) (260, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.column_stack([A_train_linear, np.full(A_train_linear.shape[0], 1)])\n",
    "T = b_train\n",
    "X_val = np.column_stack([A_validate_linear, np.full(A_validate_linear.shape[0], 1)])\n",
    "T_val = b_validate\n",
    "\n",
    "print(X.shape, T.shape, X_val.shape, T_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdad575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W0 = np.random.randn(31, 2)\n",
    "W0 = np.zeros((31,2))\n",
    "#print(X)\n",
    "#print(W0)\n",
    "#print(softmax(X @ W0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8effa8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step   1\tcost value:  0.69,\ttrain accuracy: 48.67,\tvalidation accuracy: 23.08\n",
      "Step  10\tcost value:   nan,\ttrain accuracy: 48.67,\tvalidation accuracy: 23.85\n",
      "Step  20\tcost value:   nan,\ttrain accuracy: 72.67,\tvalidation accuracy: 85.38\n",
      "Step  30\tcost value:   nan,\ttrain accuracy: 83.00,\tvalidation accuracy: 69.62\n",
      "Step  40\tcost value:   nan,\ttrain accuracy: 90.67,\tvalidation accuracy: 87.69\n",
      "Step  50\tcost value:   nan,\ttrain accuracy: 90.33,\tvalidation accuracy: 89.23\n",
      "Step  60\tcost value:   nan,\ttrain accuracy: 85.00,\tvalidation accuracy: 73.46\n",
      "Step  70\tcost value:   nan,\ttrain accuracy: 91.33,\tvalidation accuracy: 89.62\n",
      "Step  80\tcost value:   nan,\ttrain accuracy: 90.33,\tvalidation accuracy: 81.15\n",
      "Step  90\tcost value:   nan,\ttrain accuracy: 91.33,\tvalidation accuracy: 82.31\n",
      "Step 100\tcost value:   nan,\ttrain accuracy: 91.67,\tvalidation accuracy: 84.23\n",
      "Step 110\tcost value:   nan,\ttrain accuracy: 91.67,\tvalidation accuracy: 84.23\n",
      "Step 120\tcost value:   nan,\ttrain accuracy: 91.67,\tvalidation accuracy: 85.38\n",
      "Step 130\tcost value:   nan,\ttrain accuracy: 92.00,\tvalidation accuracy: 86.15\n",
      "Step 140\tcost value:   nan,\ttrain accuracy: 92.00,\tvalidation accuracy: 85.38\n",
      "Step 150\tcost value:   nan,\ttrain accuracy: 92.00,\tvalidation accuracy: 87.69\n",
      "Step 160\tcost value:   nan,\ttrain accuracy: 92.00,\tvalidation accuracy: 87.69\n",
      "Step 170\tcost value:   nan,\ttrain accuracy: 91.67,\tvalidation accuracy: 87.69\n",
      "Step 180\tcost value:   nan,\ttrain accuracy: 91.00,\tvalidation accuracy: 87.31\n",
      "Step 190\tcost value:   nan,\ttrain accuracy: 91.00,\tvalidation accuracy: 87.69\n",
      "Step 200\tcost value:   nan,\ttrain accuracy: 91.00,\tvalidation accuracy: 88.08\n",
      "Step 210\tcost value:   nan,\ttrain accuracy: 90.67,\tvalidation accuracy: 88.85\n",
      "Step 220\tcost value:   nan,\ttrain accuracy: 90.67,\tvalidation accuracy: 88.46\n",
      "Step 230\tcost value:   nan,\ttrain accuracy: 91.00,\tvalidation accuracy: 88.46\n",
      "Step 240\tcost value:   nan,\ttrain accuracy: 90.67,\tvalidation accuracy: 89.23\n",
      "Step 250\tcost value:   nan,\ttrain accuracy: 91.00,\tvalidation accuracy: 88.46\n",
      "Step 260\tcost value:   nan,\ttrain accuracy: 90.33,\tvalidation accuracy: 91.15\n",
      "Step 270\tcost value:   nan,\ttrain accuracy: 91.00,\tvalidation accuracy: 90.00\n",
      "Step 280\tcost value:   nan,\ttrain accuracy: 91.00,\tvalidation accuracy: 87.69\n",
      "Step 290\tcost value:   nan,\ttrain accuracy: 91.33,\tvalidation accuracy: 88.46\n",
      "Step 300\tcost value:   nan,\ttrain accuracy: 91.00,\tvalidation accuracy: 90.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52240/3689641830.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  return - (np.sum(T * np.log(S)) / n)\n",
      "/tmp/ipykernel_52240/3689641830.py:3: RuntimeWarning: invalid value encountered in multiply\n",
      "  return - (np.sum(T * np.log(S)) / n)\n"
     ]
    }
   ],
   "source": [
    "W = gd_fit(W0, X, T, X_val, T_val, lr=3.0, steps = 300, log_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc71a56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
